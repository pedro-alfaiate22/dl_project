{
 "cells": [
  {
   "cell_type": "code",
   "id": "729fc2d265fba467",
   "metadata": {},
   "source": [
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.preprocessing import image_dataset_from_directory\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "from sklearn.metrics import classification_report\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import os, shutil"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0e04a6af",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "def get_true_pred(model, dataset):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for images, labels in dataset.unbatch().batch(1):\n",
    "        y_true.append(np.argmax(labels.numpy()))\n",
    "        pred = model.predict(images, verbose=0)\n",
    "        y_pred.append(np.argmax(pred))\n",
    "    return np.array(y_true), np.array(y_pred)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "368c5643a7fb92b1",
   "metadata": {},
   "source": [
    "train_dir = 'Dataset/archive/seg_train'\n",
    "validation_dir = 'Dataset/archive/seg_val'\n",
    "test_dir = 'Dataset/archive/seg_test'\n",
    "\n",
    "train_buildings_dir = 'Dataset/archive/seg_train/buildings/'\n",
    "train_forest_dir = 'Dataset/archive/seg_train/forest'\n",
    "train_glacier_dir = 'Dataset/archive/seg_train/glacier'\n",
    "train_mountain_dir = 'Dataset/archive/seg_train/mountain'\n",
    "train_sea_dir = 'Dataset/archive/seg_train/sea'\n",
    "train_street_dir = 'Dataset/archive/seg_train/street'\n",
    "\n",
    "val_buildings_dir = 'Dataset/archive/seg_val/buildings'\n",
    "val_forest_dir = 'Dataset/archive/seg_val/forest'\n",
    "val_glacier_dir = 'Dataset/archive/seg_val/glacier'\n",
    "val_mountain_dir = 'Dataset/archive/seg_val/mountain'\n",
    "val_sea_dir = 'Dataset/archive/seg_val/sea'\n",
    "val_street_dir = 'Dataset/archive/seg_val/street'\n",
    "\n",
    "test_buildings_dir = 'Dataset/archive/seg_test/buildings'\n",
    "test_forest_dir = 'Dataset/archive/seg_test/forest'\n",
    "test_glacier_dir = 'Dataset/archive/seg_test/glacier'\n",
    "test_mountain_dir = 'Dataset/archive/seg_test/mountain'\n",
    "test_sea_dir = 'Dataset/archive/seg_test/sea'\n",
    "test_street_dir = 'Dataset/archive/seg_test/street'\n",
    "\n",
    "print('total training buildings images:', len(os.listdir(train_buildings_dir)))\n",
    "print('total training forest images:', len(os.listdir(train_forest_dir)))\n",
    "print('total training glacier images:', len(os.listdir(train_glacier_dir)))\n",
    "print('total training mountain images:', len(os.listdir(train_mountain_dir)))\n",
    "print('total training sea images:', len(os.listdir(train_sea_dir)))\n",
    "print('total training street images:', len(os.listdir(train_street_dir)))\n",
    "\n",
    "print('total validation buildings images:', len(os.listdir(val_buildings_dir)))\n",
    "print('total validation forest images:', len(os.listdir(val_forest_dir)))\n",
    "print('total validation glacier images:', len(os.listdir(val_glacier_dir)))\n",
    "print('total validation mountain images:', len(os.listdir(val_mountain_dir)))\n",
    "print('total validation sea images:', len(os.listdir(val_sea_dir)))\n",
    "print('total validation street images:', len(os.listdir(val_street_dir)))\n",
    "\n",
    "print('total test buildings images:', len(os.listdir(test_buildings_dir)))\n",
    "print('total test forest images:', len(os.listdir(test_forest_dir)))\n",
    "print('total test glacier images:', len(os.listdir(test_glacier_dir)))\n",
    "print('total test mountain images:', len(os.listdir(test_mountain_dir)))\n",
    "print('total test sea images:', len(os.listdir(test_sea_dir)))\n",
    "print('total test street images:', len(os.listdir(test_street_dir)))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "dd3b7c4afff89cac",
   "metadata": {},
   "source": [
    "IMG_SIZE = 150\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dataset = image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    label_mode='categorical',\n",
    "    image_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE)\n",
    "\n",
    "validation_dataset = image_dataset_from_directory(\n",
    "    validation_dir,\n",
    "    label_mode='categorical',\n",
    "    image_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE)\n",
    "\n",
    "test_dataset = image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    label_mode='categorical',\n",
    "    image_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE)\n",
    "\n",
    "print(test_dataset)\n",
    "class_names = train_dataset.class_names\n",
    "print(\"Classes:\", class_names)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "93b0a68caa19f987",
   "metadata": {},
   "source": [
    "inputs = keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "x = layers.Rescaling(1./255)(inputs)\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "x = layers.Conv2D(128, 3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "x = layers.Conv2D(128, 3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Dense(512, activation=\"relu\")(x)\n",
    "outputs = layers.Dense(len(class_names), activation=\"softmax\")(x)\n",
    "model_dropout = keras.Model(inputs, outputs)\n",
    "\n",
    "print(model_dropout.summary())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8d6586395c83fff1",
   "metadata": {},
   "source": [
    "model_dropout.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "dafadbf81fb66355",
   "metadata": {},
   "source": [
    "checkpoint_filepath = 'modelS_CatCross_RMS_dropout.keras'\n",
    "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e462cfd1bd76a4ec",
   "metadata": {},
   "source": [
    "history_dropout = model_dropout.fit(\n",
    "train_dataset,\n",
    "epochs=50,\n",
    "validation_data=validation_dataset,\n",
    "callbacks=[model_checkpoint_callback])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8e757ea6",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "best_epoch = np.argmin(history_dropout.history['val_loss']) + 1\n",
    "print(f\"Melhor Ã©poca (menor val_loss): {best_epoch}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2e25e3cb18a32986",
   "metadata": {},
   "source": [
    "model_dropout = keras.models.load_model('modelS_CatCross_RMS_dropout.keras')\n",
    "val_loss, val_acc = model_dropout.evaluate(validation_dataset)\n",
    "print('val_acc:', val_acc)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "50ff9c61cd0c2f4d",
   "metadata": {},
   "source": [
    "acc = history_dropout.history['accuracy']\n",
    "val_acc = history_dropout.history['val_accuracy']\n",
    "loss = history_dropout.history['loss']\n",
    "val_loss = history_dropout.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "de75118e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "y_true, y_pred = get_true_pred(model_dropout, test_dataset)\n",
    "report = classification_report(y_true, y_pred, target_names=class_names, output_dict=True)\n",
    "class_only_report = {k: v for k, v in report.items() if k in class_names}\n",
    "df = pd.DataFrame(class_only_report).T\n",
    "print(df[['precision', 'recall', 'f1-score']].round(3))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "458ec41edf7df352",
   "metadata": {},
   "source": [
    "inputs = keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "x = layers.Rescaling(1./255)(inputs)\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\", kernel_regularizer='l2')(x)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", kernel_regularizer='l2')(x)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "x = layers.Conv2D(128, 3, activation=\"relu\", kernel_regularizer='l2')(x)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "x = layers.Conv2D(128, 3, activation=\"relu\", kernel_regularizer='l2')(x)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(512, activation=\"relu\", kernel_regularizer='l2')(x)\n",
    "outputs = layers.Dense(len(class_names), activation=\"softmax\")(x)\n",
    "model_l2 = keras.Model(inputs, outputs)\n",
    "\n",
    "print(model_l2.summary())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c36c8004d623d6da",
   "metadata": {},
   "source": [
    "model_l2.compile(\n",
    "loss='categorical_crossentropy',\n",
    "optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-4),\n",
    "metrics=['acc'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "15f149615239dc3c",
   "metadata": {},
   "source": [
    "checkpoint_filepath = 'modelS_CatCross_RMS_L2.keras'\n",
    "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d7c5ef505ff4f57c",
   "metadata": {},
   "source": [
    "history_l2 = model_l2.fit(\n",
    "train_dataset,\n",
    "epochs=50,\n",
    "validation_data=validation_dataset,\n",
    "callbacks=[model_checkpoint_callback])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e1ff9ed5",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "best_epoch = np.argmin(history_l2.history['val_loss']) + 1\n",
    "print(f\"Melhor Ã©poca (menor val_loss): {best_epoch}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cc279d4e459b4a4",
   "metadata": {},
   "source": [
    "model_l2 = keras.models.load_model('modelS_CatCross_RMS_L2.keras')\n",
    "val_loss, val_acc = model_l2.evaluate(validation_dataset)\n",
    "print('val_acc:', val_acc)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "de1ace9c40641197",
   "metadata": {},
   "source": [
    "acc = history_l2.history['acc']\n",
    "val_acc = history_l2.history['val_acc']\n",
    "loss = history_l2.history['loss']\n",
    "val_loss = history_l2.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2272508f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "y_true, y_pred = get_true_pred(model_l2, test_dataset)\n",
    "report = classification_report(y_true, y_pred, target_names=class_names, output_dict=True)\n",
    "class_only_report = {k: v for k, v in report.items() if k in class_names}\n",
    "df = pd.DataFrame(class_only_report).T\n",
    "print(df[['precision', 'recall', 'f1-score']].round(3))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3ad17f8caf2b9d33",
   "metadata": {},
   "source": [
    "inputs = keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "x = layers.Rescaling(1./255)(inputs)\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\", kernel_regularizer='l2')(x)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", kernel_regularizer='l2')(x)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "x = layers.Conv2D(128, 3, activation=\"relu\", kernel_regularizer='l2')(x)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "x = layers.Conv2D(128, 3, activation=\"relu\", kernel_regularizer='l2')(x)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Dense(512, activation=\"relu\", kernel_regularizer='l2')(x)\n",
    "outputs = layers.Dense(len(class_names), activation=\"softmax\")(x)\n",
    "model_both = keras.Model(inputs, outputs)\n",
    "\n",
    "print(model_both.summary())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2314886d329145c6",
   "metadata": {},
   "source": [
    "model_both.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cb81a049b94aab46",
   "metadata": {},
   "source": [
    "checkpoint_filepath = 'modelS_CatCross_RMS_dropout_L2.keras'\n",
    "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "dff8d25d4e41d259",
   "metadata": {},
   "source": [
    "history_both = model_both.fit(\n",
    "train_dataset,\n",
    "epochs=50,\n",
    "validation_data=validation_dataset,\n",
    "callbacks=[model_checkpoint_callback])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9f49d155189da612",
   "metadata": {},
   "source": [
    "model_both = keras.models.load_model('modelS_CatCross_RMS_dropout_L2.keras')\n",
    "val_loss, val_acc = model_both.evaluate(validation_dataset)\n",
    "print('val_acc:', val_acc)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2e99c77ae76b4c13",
   "metadata": {},
   "source": [
    "acc = history_both.history['accuracy']\n",
    "val_acc = history_both.history['val_accuracy']\n",
    "loss_CatCros = history_both.history['loss']\n",
    "val_loss = history_both.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss_CatCros, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5d2be9ae",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "y_true, y_pred = get_true_pred(model_both, test_dataset)\n",
    "report = classification_report(y_true, y_pred, target_names=class_names, output_dict=True)\n",
    "class_only_report = {k: v for k, v in report.items() if k in class_names}\n",
    "df = pd.DataFrame(class_only_report).T\n",
    "print(df[['precision', 'recall', 'f1-score']].round(3))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f64927790136df7e",
   "metadata": {},
   "source": [
    "val_loss_CatCross_RMS_dropout, val_acc_CatCross_RMS_dropout = model_dropout.evaluate(validation_dataset)\n",
    "val_loss_CatCross_RMS_l2, val_acc_CatCross_RMS_l2 = model_l2.evaluate(validation_dataset)\n",
    "val_loss_CatCross_RMS_dropout_l2, val_acc_CatCross_RMS_dropout_l2 = model_both.evaluate(validation_dataset)\n",
    "\n",
    "print(\"Validation Accuracy dos modelos:\")\n",
    "print(f\"CatCross + RMSprop + Dropout: {val_loss_CatCross_RMS_dropout:.4f}\")\n",
    "print(f\"CatCross + RMSprop + L2: {val_loss_CatCross_RMS_l2:.4f}\")\n",
    "print(f\"CatCross + RMSprop + Dropout + L2: {val_loss_CatCross_RMS_dropout_l2:.4f}\")\n",
    "\n",
    "results = {\n",
    "    'CatCross_RMS_Dropout': val_acc_CatCross_RMS_dropout,\n",
    "    'CatCross_RMS_L2': val_acc_CatCross_RMS_l2,\n",
    "    'CatCross_RMS_Dropout_L2': val_acc_CatCross_RMS_dropout_l2\n",
    "}\n",
    "\n",
    "# Identificar o melhor modelo com base na maior val_accuracy\n",
    "best_model = max(results, key=results.get)\n",
    "best_accuracy = results[best_model]\n",
    "\n",
    "print(f\"\\nMelhor modelo: {best_model} com val_accuracy = {best_accuracy:.4f}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "013d2b09",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "y_true, y_pred = get_true_pred(model_dropout, test_dataset)\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=class_names,\n",
    "            yticklabels=class_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix - Melhor Modelo')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ffa00c2f4499d423",
   "metadata": {},
   "source": [
    "img_path = 'Dataset/archive/seg_test/sea/20072.jpg'\n",
    "\n",
    "img = tf.keras.preprocessing.image.load_img(\n",
    "    img_path,\n",
    "    target_size=(150, 150),\n",
    "    interpolation='bilinear'\n",
    ")\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.title(\"Imagem de Teste\")\n",
    "plt.show()\n",
    "\n",
    "img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0)\n",
    "\n",
    "# PrevisÃ£o\n",
    "result = model_dropout.predict(img_array)\n",
    "\n",
    "class_names = ['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']\n",
    "print(\"Probabilidades por classe:\")\n",
    "for i, prob in enumerate(result[0]):\n",
    "    print(f\"{class_names[i]:>10s}: {prob:.4f}\")\n",
    "\n",
    "# Classe prevista\n",
    "predicted_class = np.argmax(result)\n",
    "print(f\"\\nClasse prevista: {class_names[predicted_class]} ({result[0][predicted_class]:.4f})\")\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
